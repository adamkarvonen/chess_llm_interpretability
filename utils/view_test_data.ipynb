{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_piece_probe_layer_5.pkl\"\n",
    "\n",
    "with open(data_file, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "print(data['f1'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_lookup = {\n",
    "    0: \"Opp. King\",\n",
    "    1: \"Opp. Queen\",\n",
    "    2: \"Opp. Rook\",\n",
    "    3: \"Opp. Bishop\",\n",
    "    4: \"Opp. Knight\",\n",
    "    5: \"Opp. Pawn\",\n",
    "    6: \"Blank\",\n",
    "    7: \"My Pawn\",\n",
    "    8: \"My Knight\",\n",
    "    9: \"My Bishop\",\n",
    "    10: \"My Rook\",\n",
    "    11: \"My Queen\",\n",
    "    12: \"My King\",\n",
    "}\n",
    "\n",
    "header = \"| Model | \" + \" | \".join(names_lookup.values()) + \" |\"\n",
    "separator = \"| --- | \" + \" | \".join(['---']*len(names_lookup)) + \" |\"\n",
    "\n",
    "print(header)\n",
    "print(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "data_files = {\n",
    "    \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_piece_probe_layer_5.pkl\": \"8 Layer Model\",\n",
    "    \"tf_lens_lichess_16layers_ckpt_no_optimizer_chess_piece_probe_layer_11.pkl\": \"16 Layer Model\",\n",
    "    \"tf_lens_randominit_8layers_ckpt_no_optimizer_chess_piece_probe_layer_5.pkl\": \"8 Layer Random Init\",\n",
    "    \"tf_lens_randominit_16layers_ckpt_no_optimizer_chess_piece_probe_layer_11.pkl\": \"16 Layer Random Init\",\n",
    "}\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_threat_probe_layer_5.pkl\"\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_legal_move_probe_layer_5.pkl\"\n",
    "all_data_rows = []\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Load the data\n",
    "    with open(data_file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Prepare to accumulate the sums\n",
    "    sum_dict = {'f1': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1']],\n",
    "                # 'f1_no_blank': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank']],\n",
    "                # 'f1_no_blank_initial': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank_initial']],\n",
    "                }\n",
    "\n",
    "    # Sum the tensors across all dicts\n",
    "    for entry in data['f1']:\n",
    "        for key in sum_dict:\n",
    "            for i, tensor in enumerate(entry[key]):\n",
    "                sum_dict[key][i] += tensor\n",
    "\n",
    "    num_datapoints = len(data['f1'])\n",
    "\n",
    "    for key in sum_dict:\n",
    "        for i in range(len(sum_dict[key])):\n",
    "            if sum_dict[key][i].dtype == torch.float32:\n",
    "                sum_dict[key][i] /= num_datapoints\n",
    "\n",
    "    # Check the resulting sums (optional)\n",
    "    print({key: [tensor.tolist() for tensor in tensors] for key, tensors in sum_dict.items()})\n",
    "\n",
    "    # Create the data rows\n",
    "    data_rows = [data_files[data_file]] \n",
    "    for idx, f1 in enumerate(sum_dict['f1'][1]):\n",
    "        data_rows.append(f\"{f1:.3f}\")\n",
    "\n",
    "    data_row = \"| \" + \" | \".join(data_rows) + \" |\"\n",
    "    all_data_rows.append(data_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header)\n",
    "print(separator)\n",
    "for data_row in all_data_rows:\n",
    "    print(data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_lookup = {\n",
    "    0: \"Opp. King\",\n",
    "    1: \"Opp. Queen\",\n",
    "    2: \"Opp. Rook\",\n",
    "    3: \"Opp. Bishop\",\n",
    "    4: \"Opp. Knight\",\n",
    "    5: \"Opp. Pawn\",\n",
    "    6: \"Blank\",\n",
    "    7: \"My Pawn\",\n",
    "    8: \"My Knight\",\n",
    "    9: \"My Bishop\",\n",
    "    10: \"My Rook\",\n",
    "    11: \"My Queen\",\n",
    "    12: \"My King\",\n",
    "}\n",
    "\n",
    "print(sum_dict['f1'][1])\n",
    "\n",
    "for idx, f1 in enumerate(sum_dict['f1'][1]):\n",
    "    print(f\"{names_lookup[idx]}: {f1.item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"| \" + \" | \".join(names_lookup.values()) + \" |\"\n",
    "separator = \"| \" + \" | \".join(['---']*len(names_lookup)) + \" |\"\n",
    "\n",
    "# Create the data rows\n",
    "data_rows = []\n",
    "for idx, f1 in enumerate(sum_dict['f1'][1]):\n",
    "    data_rows.append(f\"{f1:.3f}\")\n",
    "\n",
    "data_row = \"| \" + \" | \".join(data_rows) + \" |\"\n",
    "\n",
    "# Print markdown table\n",
    "print(header)\n",
    "print(separator)\n",
    "print(data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "data_files = {\n",
    "    \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_piece_probe_layer_5.pkl\": \"8 Layer Model\",\n",
    "    \"tf_lens_randominit_8layers_ckpt_no_optimizer_chess_piece_probe_layer_5.pkl\": \"8 Layer Random Init\",\n",
    "}\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_threat_probe_layer_5.pkl\"\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_legal_move_probe_layer_5.pkl\"\n",
    "all_data_rows = []\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Load the data\n",
    "    with open(data_file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Prepare to accumulate the sums\n",
    "    sum_dict = {'f1': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1']],\n",
    "                'f1_no_blank': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank']],\n",
    "                'f1_no_blank_initial': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank_initial']],\n",
    "                }\n",
    "\n",
    "    # Sum the tensors across all dicts\n",
    "    for entry in data['f1']:\n",
    "        for key in sum_dict:\n",
    "            for i, tensor in enumerate(entry[key]):\n",
    "                sum_dict[key][i] += tensor\n",
    "\n",
    "    num_datapoints = len(data['f1'])\n",
    "\n",
    "    for key in sum_dict:\n",
    "        for i in range(len(sum_dict[key])):\n",
    "            if sum_dict[key][i].dtype == torch.float32:\n",
    "                sum_dict[key][i] /= num_datapoints\n",
    "    print(data_file)\n",
    "    print(sum_dict['f1_no_blank_initial'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "data_files = {\n",
    "    \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_legal_move_probe_layer_5.pkl\": \"8 Layer Model\",\n",
    "    \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_threat_probe_layer_5.pkl\": \"8 Layer Model\",\n",
    "    \"tf_lens_randominit_8layers_ckpt_no_optimizer_chess_legal_move_probe_layer_5.pkl\": \"8 Layer Random Init\",\n",
    "    \"tf_lens_randominit_8layers_ckpt_no_optimizer_chess_threat_probe_layer_5.pkl\": \"8 Layer Random Init\",\n",
    "}\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_threat_probe_layer_5.pkl\"\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_legal_move_probe_layer_5.pkl\"\n",
    "all_data_rows = []\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Load the data\n",
    "    with open(data_file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Prepare to accumulate the sums\n",
    "    sum_dict = {'f1': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1']],\n",
    "                # 'f1_no_blank': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank']],\n",
    "                # 'f1_no_blank_initial': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank_initial']],\n",
    "                }\n",
    "\n",
    "    # Sum the tensors across all dicts\n",
    "    for entry in data['f1']:\n",
    "        for key in sum_dict:\n",
    "            for i, tensor in enumerate(entry[key]):\n",
    "                sum_dict[key][i] += tensor\n",
    "\n",
    "    num_datapoints = len(data['f1'])\n",
    "\n",
    "    for key in sum_dict:\n",
    "        for i in range(len(sum_dict[key])):\n",
    "            if sum_dict[key][i].dtype == torch.float32:\n",
    "                sum_dict[key][i] /= num_datapoints\n",
    "    print(data_file)\n",
    "    print(sum_dict['f1'][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "data_files = {\n",
    "    \"Othello-GPT-Transformer-Lens_othello_mine_yours_probe_layer_5.pkl\": \"8 Layer Model\",\n",
    "}\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_threat_probe_layer_5.pkl\"\n",
    "# data_file = \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_legal_move_probe_layer_5.pkl\"\n",
    "all_data_rows = []\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Load the data\n",
    "    with open(data_file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Prepare to accumulate the sums\n",
    "    sum_dict = {'f1': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1']],\n",
    "                'f1_no_blank': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank']],\n",
    "                # 'f1_no_blank_initial': [torch.zeros_like(tensor) for tensor in data['f1'][0]['f1_no_blank_initial']],\n",
    "                }\n",
    "\n",
    "    # Sum the tensors across all dicts\n",
    "    for entry in data['f1']:\n",
    "        for key in sum_dict:\n",
    "            for i, tensor in enumerate(entry[key]):\n",
    "                sum_dict[key][i] += tensor\n",
    "\n",
    "    num_datapoints = len(data['f1'])\n",
    "\n",
    "    for key in sum_dict:\n",
    "        for i in range(len(sum_dict[key])):\n",
    "            if sum_dict[key][i].dtype == torch.float32:\n",
    "                sum_dict[key][i] /= num_datapoints\n",
    "    print(data_file)\n",
    "    print(sum_dict['f1_no_blank'][0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
